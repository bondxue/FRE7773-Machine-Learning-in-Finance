{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 5\n",
    "#### Assigned: 2019-04-25\n",
    "#### Due EOD: 2019-05-02\n",
    "\n",
    "Based on Lecture 12\n",
    "+ The student fills in the <...> fields.  \n",
    "+ The student can create as many new cells as necessary in the solution sections."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Make sure you have activated the correct python envorinment**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Name:  Mengheng Xue\n",
    "#### NetID: mx586"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1 (20 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A CNN has the following structure:  \n",
    "\n",
    "Conv2D_Layer -> Pooling_Layer -> Flattening_Layer -> Dense_Layer\n",
    "\n",
    "+ input shape (size of the image): $M_1 \\times M_2$\n",
    "+ conv2d kernel with bias\n",
    "+ conv2d kernel shape: $K_1 \\times K_2$  \n",
    "+ conv2d padding: same  \n",
    "+ conv2d stride in both dimensions: 1  \n",
    "+ conv2d filters (number of kernels): $F$\n",
    "+ pooling layer size: $P_1 \\times P_2$ (assume $P_{1,2}$ is a divisor of $M_{1,2}$) \n",
    "+ pooling padding: same\n",
    "+ pooling stride in both dimensions: 1\n",
    "+ flattening layer  \n",
    "+ dense layer with bias\n",
    "+ dense layer units (number of nodes): $H$\n",
    "\n",
    "Write down the expression that gives the total number of parameters to be fitted $Q$ in terms of the above values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conv2D_Layer: $(K_1\\times K_2+1)\\times F$ \n",
    "\n",
    "Pooling_Layer: $0$\n",
    "\n",
    "Flattening_Layer: $(M_1\\times M_2\\times F + 1)\\times H$\n",
    "\n",
    "Therefore, $Q = (K_1\\times K_2+1)\\times F +(M_1\\times M_2\\times F + 1) \\times H $\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2 (80 points) \n",
    "\n",
    "Use LSTM to analyze S&P 500 returns over the period 2004-2006.\n",
    "\n",
    "The data file \"stock-treasury-2004_2006.csv\", to be found in the \"Data\" folder, contains the following:  \n",
    "+ TREAS_3M: the yield of the 3-month treasury note in percent (i.e 2.1 means 2.1%)\n",
    "+ Adjusted close price of ten major stocks: GM, F, UTX, CAT, MRK, PFE, IBM, MSFT, C, XOM\n",
    "+ SP: The S&P 500 equity index level at the close of the trading day  \n",
    "\n",
    "**Do the following:**  \n",
    "\n",
    "Use the pandas read_csv function to read the Date and SP columns in a data frame called \"sp_df\".  \n",
    "Rename the \"SP\" column into \"ClosePx\" in the same read_csv call.  \n",
    "Compute the close-to-close index returns as:  $r_t = P_{t+1}/P_t - 1$ and add them as a new column \"DailyRet\".  \n",
    "It is recommended to express all daily returns in basis points (10,000 bps = 100% = 1)\n",
    "\n",
    "We want to train an RNN that looks back $M$ days and forecasts forward $N$ days.  \n",
    "Therefore the RNN will use return sequences of size $M$, and targets of size $N$.  \n",
    "\n",
    "Reformat the return data suitable for RNN processing as follows.  \n",
    "From the \"DailyRet\" column of \"sp_df\", create a data input matrix $X$ containing rows as below:    \n",
    "$$r_0, r_1, r_2, \\ldots, r_{M-1}$$  \n",
    "$$r_1, r_2, r_3, \\ldots, r_{M}$$  \n",
    "$$r_2, r_3, r_4, \\ldots, r_{M+1}$$  \n",
    "$$\\ldots$$\n",
    "From the \"DailyRet\" column of \"sp_df\", create also a target matrix $y$ containing rows as below:\n",
    "$$ r_{M}, r_{M+1}, \\ldots, r_{M+N-1}$$\n",
    "$$ r_{M+1}, r_{M+2}, \\ldots, r_{M+N}$$\n",
    "$$ r_{M+2}, r_{M+3}, \\ldots, r_{M+N+1}$$\n",
    "$$\\ldots$$\n",
    "\n",
    "Set $M=16$ and $N=4$.  \n",
    "Build an RNN with two LSTM cells and train it on the first 607 sequences.  \n",
    "This means that the training set contains returns with the latest date of 2016-05-31.    \n",
    "Use the remaining returns for out-of-sample testing.  \n",
    "This is a regression task, so train the network using mean_squared_error loss.  \n",
    "When connecting the two LSTMs, make sure you set the parameter return_sequences=True on the first LSTM, \n",
    "so that the second can see the sequences.\n",
    "\n",
    "Compute the out-of-sample actual and predicted 2-day, 3-day, ..., N-day return, by summing 1-day forward returns up to this horizon.  \n",
    "N-day return is the return from today's close to the close of the N-th day forward from today.  \n",
    "Calculate and report the RMSE and the correlation between actual and predicted 1-day, 2-day, ..., N-day returns.  \n",
    "Plot the actual and predicted returns in the out-of-sample part.  \n",
    "What do you conclude regarding the quality of the forecasts?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>TREAS_3M</th>\n",
       "      <th>GM</th>\n",
       "      <th>F</th>\n",
       "      <th>UTX</th>\n",
       "      <th>CAT</th>\n",
       "      <th>MRK</th>\n",
       "      <th>PFE</th>\n",
       "      <th>IBM</th>\n",
       "      <th>MSFT</th>\n",
       "      <th>C</th>\n",
       "      <th>XOM</th>\n",
       "      <th>SP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>02-Jan-04</td>\n",
       "      <td>0.91</td>\n",
       "      <td>46.72</td>\n",
       "      <td>14.55</td>\n",
       "      <td>45.13</td>\n",
       "      <td>39.35</td>\n",
       "      <td>41.76</td>\n",
       "      <td>32.85</td>\n",
       "      <td>89.10</td>\n",
       "      <td>24.00</td>\n",
       "      <td>44.17</td>\n",
       "      <td>38.31</td>\n",
       "      <td>1108.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>05-Jan-04</td>\n",
       "      <td>0.90</td>\n",
       "      <td>47.55</td>\n",
       "      <td>15.02</td>\n",
       "      <td>45.40</td>\n",
       "      <td>40.42</td>\n",
       "      <td>42.60</td>\n",
       "      <td>33.73</td>\n",
       "      <td>90.56</td>\n",
       "      <td>24.60</td>\n",
       "      <td>44.88</td>\n",
       "      <td>39.20</td>\n",
       "      <td>1122.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>06-Jan-04</td>\n",
       "      <td>0.90</td>\n",
       "      <td>47.26</td>\n",
       "      <td>14.97</td>\n",
       "      <td>45.29</td>\n",
       "      <td>39.70</td>\n",
       "      <td>42.40</td>\n",
       "      <td>33.71</td>\n",
       "      <td>90.57</td>\n",
       "      <td>24.69</td>\n",
       "      <td>44.93</td>\n",
       "      <td>38.94</td>\n",
       "      <td>1123.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>07-Jan-04</td>\n",
       "      <td>0.89</td>\n",
       "      <td>47.91</td>\n",
       "      <td>15.38</td>\n",
       "      <td>45.43</td>\n",
       "      <td>39.27</td>\n",
       "      <td>42.45</td>\n",
       "      <td>34.00</td>\n",
       "      <td>90.30</td>\n",
       "      <td>24.66</td>\n",
       "      <td>44.99</td>\n",
       "      <td>38.65</td>\n",
       "      <td>1126.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>08-Jan-04</td>\n",
       "      <td>0.86</td>\n",
       "      <td>47.90</td>\n",
       "      <td>15.48</td>\n",
       "      <td>45.38</td>\n",
       "      <td>38.97</td>\n",
       "      <td>42.67</td>\n",
       "      <td>33.68</td>\n",
       "      <td>90.55</td>\n",
       "      <td>24.62</td>\n",
       "      <td>45.18</td>\n",
       "      <td>38.56</td>\n",
       "      <td>1131.92</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date  TREAS_3M     GM      F    UTX    CAT    MRK    PFE    IBM  \\\n",
       "0  02-Jan-04      0.91  46.72  14.55  45.13  39.35  41.76  32.85  89.10   \n",
       "1  05-Jan-04      0.90  47.55  15.02  45.40  40.42  42.60  33.73  90.56   \n",
       "2  06-Jan-04      0.90  47.26  14.97  45.29  39.70  42.40  33.71  90.57   \n",
       "3  07-Jan-04      0.89  47.91  15.38  45.43  39.27  42.45  34.00  90.30   \n",
       "4  08-Jan-04      0.86  47.90  15.48  45.38  38.97  42.67  33.68  90.55   \n",
       "\n",
       "    MSFT      C    XOM       SP  \n",
       "0  24.00  44.17  38.31  1108.48  \n",
       "1  24.60  44.88  39.20  1122.22  \n",
       "2  24.69  44.93  38.94  1123.67  \n",
       "3  24.66  44.99  38.65  1126.33  \n",
       "4  24.62  45.18  38.56  1131.92  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import libraries \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# import the dataset  \n",
    "dataset = pd.read_csv('stock-treasury-2004_2006.csv')\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>SP</th>\n",
       "      <th>DailyRet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>05-Jan-04</td>\n",
       "      <td>1122.22</td>\n",
       "      <td>123.953522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>06-Jan-04</td>\n",
       "      <td>1123.67</td>\n",
       "      <td>12.920818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>07-Jan-04</td>\n",
       "      <td>1126.33</td>\n",
       "      <td>23.672431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>08-Jan-04</td>\n",
       "      <td>1131.92</td>\n",
       "      <td>49.630215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>09-Jan-04</td>\n",
       "      <td>1121.86</td>\n",
       "      <td>-88.875539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>12-Jan-04</td>\n",
       "      <td>1127.23</td>\n",
       "      <td>47.866935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>13-Jan-04</td>\n",
       "      <td>1121.22</td>\n",
       "      <td>-53.316537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>14-Jan-04</td>\n",
       "      <td>1130.52</td>\n",
       "      <td>82.945363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>15-Jan-04</td>\n",
       "      <td>1132.05</td>\n",
       "      <td>13.533595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>16-Jan-04</td>\n",
       "      <td>1139.83</td>\n",
       "      <td>68.724880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>20-Jan-04</td>\n",
       "      <td>1138.77</td>\n",
       "      <td>-9.299632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>21-Jan-04</td>\n",
       "      <td>1147.62</td>\n",
       "      <td>77.715430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>22-Jan-04</td>\n",
       "      <td>1143.94</td>\n",
       "      <td>-32.066363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>23-Jan-04</td>\n",
       "      <td>1141.55</td>\n",
       "      <td>-20.892704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>26-Jan-04</td>\n",
       "      <td>1155.37</td>\n",
       "      <td>121.063466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>27-Jan-04</td>\n",
       "      <td>1144.05</td>\n",
       "      <td>-97.977271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>28-Jan-04</td>\n",
       "      <td>1128.48</td>\n",
       "      <td>-136.095450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>29-Jan-04</td>\n",
       "      <td>1134.11</td>\n",
       "      <td>49.890118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>30-Jan-04</td>\n",
       "      <td>1131.13</td>\n",
       "      <td>-26.276111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>02-Feb-04</td>\n",
       "      <td>1135.26</td>\n",
       "      <td>36.512160</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date       SP    DailyRet\n",
       "1   05-Jan-04  1122.22  123.953522\n",
       "2   06-Jan-04  1123.67   12.920818\n",
       "3   07-Jan-04  1126.33   23.672431\n",
       "4   08-Jan-04  1131.92   49.630215\n",
       "5   09-Jan-04  1121.86  -88.875539\n",
       "6   12-Jan-04  1127.23   47.866935\n",
       "7   13-Jan-04  1121.22  -53.316537\n",
       "8   14-Jan-04  1130.52   82.945363\n",
       "9   15-Jan-04  1132.05   13.533595\n",
       "10  16-Jan-04  1139.83   68.724880\n",
       "11  20-Jan-04  1138.77   -9.299632\n",
       "12  21-Jan-04  1147.62   77.715430\n",
       "13  22-Jan-04  1143.94  -32.066363\n",
       "14  23-Jan-04  1141.55  -20.892704\n",
       "15  26-Jan-04  1155.37  121.063466\n",
       "16  27-Jan-04  1144.05  -97.977271\n",
       "17  28-Jan-04  1128.48 -136.095450\n",
       "18  29-Jan-04  1134.11   49.890118\n",
       "19  30-Jan-04  1131.13  -26.276111\n",
       "20  02-Feb-04  1135.26   36.512160"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp_df = dataset.loc[:, ['Date', 'SP']] # create sp_df \n",
    "sp = sp_df.loc[:, 'SP'].values\n",
    "dr = [(sp[i+1] / sp[i] -1)*10000 for i in range(len(sp)-1)]  # daily return calculation \n",
    "sp_df.drop(sp_df.index[0], inplace=True) # remove first row \n",
    "sp_df['DailyRet'] = dr\n",
    "data_raw = sp_df.iloc[:, 2:3].values\n",
    "sp_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of entries (training set, test set): (607, 65)\n",
      "Original training data shape:\n",
      "(588, 16)\n",
      "(588, 4)\n",
      "New training data shape:\n",
      "(588, 16, 1)\n"
     ]
    }
   ],
   "source": [
    "# Feature Scaling\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler(feature_range = (0, 1))\n",
    "dataset = scaler.fit_transform(data_raw)\n",
    "\n",
    "train_size = 607\n",
    "test_size = len(dataset) - train_size\n",
    "train, test = dataset[0:train_size, :], dataset[train_size:len(dataset), :]\n",
    "print(\"Number of entries (training set, test set): \" + str((len(train), len(test))))\n",
    "\n",
    "# function to create train and test set\n",
    "def create_dataset(dataset, train_window_size=16, test_window_size=4):\n",
    "    data_X, data_Y = [], []\n",
    "    for i in range(len(dataset) - train_window_size-test_window_size + 1):\n",
    "        a = dataset[i:(i + train_window_size), 0]\n",
    "        b = dataset[(i+train_window_size):(i+train_window_size+test_window_size), 0]\n",
    "        data_X.append(a)\n",
    "        data_Y.append(b)\n",
    "    return(np.array(data_X), np.array(data_Y))\n",
    "\n",
    "train_X, train_y = create_dataset(train)\n",
    "test_X, test_y = create_dataset(test)\n",
    "print(\"Original training data shape:\")\n",
    "print(train_X.shape)\n",
    "print(train_y.shape)\n",
    "\n",
    "# Reshape the input data into appropriate form for Keras.\n",
    "train_X = np.reshape(train_X, (train_X.shape[0], train_X.shape[1], 1))\n",
    "test_X = np.reshape(test_X, (test_X.shape[0], test_X.shape[1], 1))\n",
    "print(\"New training data shape:\")\n",
    "print(train_X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Importing the Keras libraries and packages\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 16, 80)            26240     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 16, 80)            0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 80)                51520     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 80)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4)                 324       \n",
      "=================================================================\n",
      "Total params: 78,084\n",
      "Trainable params: 78,084\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def build_model(window_size = 16):\n",
    "    model = Sequential() \n",
    "    model.add(LSTM(input_shape = (window_size, 1), units=80, return_sequences = True, activation='relu')) # add first LSTM layer \n",
    "    model.add(Dropout(0.2))# dropout regulization to avoid overfitting\n",
    "    model.add(LSTM(input_shape=(window_size, 1), units=80, return_sequences = False, activation='relu')) # add second LSTM layer \n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(units = 4, kernel_initializer = 'uniform', activation = 'linear'))\n",
    "    model.summary()\n",
    "    return(model)\n",
    "\n",
    "model = build_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# compile, fit and evaluate\n",
    "def fit_model(model, train_X, train_y):\n",
    "    model.compile(loss='mean_squared_error', optimizer='RMSprop', metrics=['mean_absolute_error']) \n",
    "    es = EarlyStopping(monitor='val_loss', min_delta=0, patience=3, mode='auto', baseline=None)\n",
    "    model.fit( train_X, train_y, batch_size=50, epochs=100, validation_split=0.1, callbacks=[es], verbose=1)\n",
    "    return model\n",
    "    \n",
    "model_fit = fit_model(model, train_X, train_y)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model predicting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predit_model(model_fit, test_X, test_y):\n",
    "    pred = scaler.inverse_transform(model_fit.predict(test_X))\n",
    "    actual = scaler.inverse_transform((test_y))\n",
    "    return pred, actual \n",
    "\n",
    "pred, actual = predit_model(model_fit, test_X, test_y)\n",
    "\n",
    "# function obtain n-day return \n",
    "def nday_return(return_data, n):\n",
    "    nday_return = return_data[:,0]\n",
    "    if (n==0):\n",
    "        return nday_return\n",
    "    else:\n",
    "        for i in range(1,n+1):\n",
    "            nday_return = nday_return + return_data[:, i]\n",
    "        return nday_return "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate performance by RMSE & correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "\n",
    "for i in range(4):\n",
    "    print(\"{}-day return RMSE: {:0.2f}\".format(i+1, sqrt(mean_squared_error(nday_return(actual, i), nday_return(pred, i)))))\n",
    "print(\"\\n\")  \n",
    "\n",
    "for i in range(4):\n",
    "    print(\"{}-day return correlation: {:0.2f}\".format(i+1, np.corrcoef(nday_return(actual, i), nday_return(pred, i))[0,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ We can see that LSTM cannot predict the daily return well. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the plot.\n",
    "plt.style.use('seaborn')\n",
    "plt.rcParams['figure.figsize'] = (20, 10)\n",
    "plt.rcParams['legend.fontsize'] = 'x-large'\n",
    "plt.rcParams['axes.labelsize'] = 'x-large'\n",
    "plt.rcParams['axes.titlesize'] = 'x-large'\n",
    "plt.rcParams['xtick.labelsize'] = 'x-large'\n",
    "plt.rcParams['ytick.labelsize'] = 'x-large'\n",
    "\n",
    "# Visualising 1-day return \n",
    "plt.plot(nday_return(actual, 0), color = 'blue', label = 'real one day return')\n",
    "plt.plot(nday_return(pred, 0), color = 'red', label = 'predicted one day return')\n",
    "plt.title('one day return preditcion')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('one day return')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualising 2-day return \n",
    "plt.plot(nday_return(actual, 1), color = 'blue', label = 'real two day return')\n",
    "plt.plot(nday_return(pred, 1), color = 'red', label = 'predicted two day return')\n",
    "plt.title('two day return preditcion')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('two day return')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualising 3-day return \n",
    "plt.plot(nday_return(actual, 2), color = 'blue', label = 'real three day return')\n",
    "plt.plot(nday_return(pred, 2), color = 'red', label = 'predicted three day return')\n",
    "plt.title('three day return preditcion')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('three day return')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualising 4-day return\n",
    "plt.plot(nday_return(actual, 3), color = 'blue', label = 'real four day return')\n",
    "plt.plot(nday_return(pred, 0), color = 'red', label = 'predicted four day return')\n",
    "plt.title('four day return preditcion')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('four day return')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Q: What do you conclude regarding the quality of the forecasts?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on RMSE and correlation between acutal and predicted n-day returns  and plots of out-of-sample parts, we can conclude that LSTM model does not have good performance in predicting daily returns. The potential reseaons are:\n",
    "1. Daily return has martingale property, we cannot predict daily returns just based on the previous daily return data. \n",
    "2. If we want to improve the prediction performance, instead of using just previous daily return data, more features needed to be considered, such as volume.\n",
    "3. Even with enough data and good feature selection, we still cannot expect much better performace. As we could see from the real daily return plots, daily return does not have obvious trends and it is extremly unstable with sudden nonlinear changes. However, LSTM only based on the previous information, for which I doubt it could capture the super nonlinear trends. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

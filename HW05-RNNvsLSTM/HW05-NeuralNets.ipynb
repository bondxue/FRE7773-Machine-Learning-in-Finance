{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 5\n",
    "#### Assigned: 2019-04-25\n",
    "#### Due EOD: 2019-05-02\n",
    "\n",
    "Based on Lecture 12\n",
    "+ The student fills in the <...> fields.  \n",
    "+ The student can create as many new cells as necessary in the solution sections."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Make sure you have activated the correct python envorinment**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Name:  Mengheng Xue\n",
    "#### NetID: mx586"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1 (20 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A CNN has the following structure:  \n",
    "\n",
    "Conv2D_Layer -> Pooling_Layer -> Flattening_Layer -> Dense_Layer\n",
    "\n",
    "+ input shape (size of the image): $M_1 \\times M_2$\n",
    "+ conv2d kernel with bias\n",
    "+ conv2d kernel shape: $K_1 \\times K_2$  \n",
    "+ conv2d padding: same  \n",
    "+ conv2d stride in both dimensions: 1  \n",
    "+ conv2d filters (number of kernels): $F$\n",
    "+ pooling layer size: $P_1 \\times P_2$ (assume $P_{1,2}$ is a divisor of $M_{1,2}$) \n",
    "+ pooling padding: same\n",
    "+ pooling stride in both dimensions: 1\n",
    "+ flattening layer  \n",
    "+ dense layer with bias\n",
    "+ dense layer units (number of nodes): $H$\n",
    "\n",
    "Write down the expression that gives the total number of parameters to be fitted $Q$ in terms of the above values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<...>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2 (80 points) \n",
    "\n",
    "Use LSTM to analyze S&P 500 returns over the period 2004-2006.\n",
    "\n",
    "The data file \"stock-treasury-2004_2006.csv\", to be found in the \"Data\" folder, contains the following:  \n",
    "+ TREAS_3M: the yield of the 3-month treasury note in percent (i.e 2.1 means 2.1%)\n",
    "+ Adjusted close price of ten major stocks: GM, F, UTX, CAT, MRK, PFE, IBM, MSFT, C, XOM\n",
    "+ SP: The S&P 500 equity index level at the close of the trading day  \n",
    "\n",
    "**Do the following:**  \n",
    "\n",
    "Use the pandas read_csv function to read the Date and SP columns in a data frame called \"sp_df\".  \n",
    "Rename the \"SP\" column into \"ClosePx\" in the same read_csv call.  \n",
    "Compute the close-to-close index returns as:  $r_t = P_{t+1}/P_t - 1$ and add them as a new column \"DailyRet\".  \n",
    "It is recommended to express all daily returns in basis points (10,000 bps = 100% = 1)\n",
    "\n",
    "We want to train an RNN that looks back $M$ days and forecasts forward $N$ days.  \n",
    "Therefore the RNN will use return sequences of size $M$, and targets of size $N$.  \n",
    "\n",
    "Reformat the return data suitable for RNN processing as follows.  \n",
    "From the \"DailyRet\" column of \"sp_df\", create a data input matrix $X$ containing rows as below:    \n",
    "$$r_0, r_1, r_2, \\ldots, r_{M-1}$$  \n",
    "$$r_1, r_2, r_3, \\ldots, r_{M}$$  \n",
    "$$r_2, r_3, r_4, \\ldots, r_{M+1}$$  \n",
    "$$\\ldots$$\n",
    "From the \"DailyRet\" column of \"sp_df\", create also a target matrix $y$ containing rows as below:\n",
    "$$ r_{M}, r_{M+1}, \\ldots, r_{M+N-1}$$\n",
    "$$ r_{M+1}, r_{M+2}, \\ldots, r_{M+N}$$\n",
    "$$ r_{M+2}, r_{M+3}, \\ldots, r_{M+N+1}$$\n",
    "$$\\ldots$$\n",
    "\n",
    "Set $M=16$ and $N=4$.  \n",
    "Build an RNN with two LSTM cells and train it on the first 607 sequences.  \n",
    "This means that the training set contains returns with the latest date of 2016-05-31.    \n",
    "Use the remaining returns for out-of-sample testing.  \n",
    "This is a regression task, so train the network using mean_squared_error loss.  \n",
    "When connecting the two LSTMs, make sure you set the parameter return_sequences=True on the first LSTM, \n",
    "so that the second can see the sequences.\n",
    "\n",
    "Compute the out-of-sample actual and predicted 2-day, 3-day, ..., N-day return, by summing 1-day forward returns up to this horizon.  \n",
    "N-day return is the return from today's close to the close of the N-th day forward from today.  \n",
    "Calculate and report the RMSE and the correlation between actual and predicted 1-day, 2-day, ..., N-day returns.  \n",
    "Plot the actual and predicted returns in the out-of-sample part.  \n",
    "What do you conclude regarding the quality of the forecasts?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>TREAS_3M</th>\n",
       "      <th>GM</th>\n",
       "      <th>F</th>\n",
       "      <th>UTX</th>\n",
       "      <th>CAT</th>\n",
       "      <th>MRK</th>\n",
       "      <th>PFE</th>\n",
       "      <th>IBM</th>\n",
       "      <th>MSFT</th>\n",
       "      <th>C</th>\n",
       "      <th>XOM</th>\n",
       "      <th>SP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>02-Jan-04</td>\n",
       "      <td>0.91</td>\n",
       "      <td>46.72</td>\n",
       "      <td>14.55</td>\n",
       "      <td>45.13</td>\n",
       "      <td>39.35</td>\n",
       "      <td>41.76</td>\n",
       "      <td>32.85</td>\n",
       "      <td>89.10</td>\n",
       "      <td>24.00</td>\n",
       "      <td>44.17</td>\n",
       "      <td>38.31</td>\n",
       "      <td>1108.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>05-Jan-04</td>\n",
       "      <td>0.90</td>\n",
       "      <td>47.55</td>\n",
       "      <td>15.02</td>\n",
       "      <td>45.40</td>\n",
       "      <td>40.42</td>\n",
       "      <td>42.60</td>\n",
       "      <td>33.73</td>\n",
       "      <td>90.56</td>\n",
       "      <td>24.60</td>\n",
       "      <td>44.88</td>\n",
       "      <td>39.20</td>\n",
       "      <td>1122.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>06-Jan-04</td>\n",
       "      <td>0.90</td>\n",
       "      <td>47.26</td>\n",
       "      <td>14.97</td>\n",
       "      <td>45.29</td>\n",
       "      <td>39.70</td>\n",
       "      <td>42.40</td>\n",
       "      <td>33.71</td>\n",
       "      <td>90.57</td>\n",
       "      <td>24.69</td>\n",
       "      <td>44.93</td>\n",
       "      <td>38.94</td>\n",
       "      <td>1123.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>07-Jan-04</td>\n",
       "      <td>0.89</td>\n",
       "      <td>47.91</td>\n",
       "      <td>15.38</td>\n",
       "      <td>45.43</td>\n",
       "      <td>39.27</td>\n",
       "      <td>42.45</td>\n",
       "      <td>34.00</td>\n",
       "      <td>90.30</td>\n",
       "      <td>24.66</td>\n",
       "      <td>44.99</td>\n",
       "      <td>38.65</td>\n",
       "      <td>1126.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>08-Jan-04</td>\n",
       "      <td>0.86</td>\n",
       "      <td>47.90</td>\n",
       "      <td>15.48</td>\n",
       "      <td>45.38</td>\n",
       "      <td>38.97</td>\n",
       "      <td>42.67</td>\n",
       "      <td>33.68</td>\n",
       "      <td>90.55</td>\n",
       "      <td>24.62</td>\n",
       "      <td>45.18</td>\n",
       "      <td>38.56</td>\n",
       "      <td>1131.92</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date  TREAS_3M     GM      F    UTX    CAT    MRK    PFE    IBM  \\\n",
       "0  02-Jan-04      0.91  46.72  14.55  45.13  39.35  41.76  32.85  89.10   \n",
       "1  05-Jan-04      0.90  47.55  15.02  45.40  40.42  42.60  33.73  90.56   \n",
       "2  06-Jan-04      0.90  47.26  14.97  45.29  39.70  42.40  33.71  90.57   \n",
       "3  07-Jan-04      0.89  47.91  15.38  45.43  39.27  42.45  34.00  90.30   \n",
       "4  08-Jan-04      0.86  47.90  15.48  45.38  38.97  42.67  33.68  90.55   \n",
       "\n",
       "    MSFT      C    XOM       SP  \n",
       "0  24.00  44.17  38.31  1108.48  \n",
       "1  24.60  44.88  39.20  1122.22  \n",
       "2  24.69  44.93  38.94  1123.67  \n",
       "3  24.66  44.99  38.65  1126.33  \n",
       "4  24.62  45.18  38.56  1131.92  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import libraries \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# import the dataset  \n",
    "dataset = pd.read_csv('stock-treasury-2004_2006.csv')\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>SP</th>\n",
       "      <th>DailyRet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>05-Jan-04</td>\n",
       "      <td>1122.22</td>\n",
       "      <td>123.953522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>06-Jan-04</td>\n",
       "      <td>1123.67</td>\n",
       "      <td>12.920818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>07-Jan-04</td>\n",
       "      <td>1126.33</td>\n",
       "      <td>23.672431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>08-Jan-04</td>\n",
       "      <td>1131.92</td>\n",
       "      <td>49.630215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>09-Jan-04</td>\n",
       "      <td>1121.86</td>\n",
       "      <td>-88.875539</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date       SP    DailyRet\n",
       "1  05-Jan-04  1122.22  123.953522\n",
       "2  06-Jan-04  1123.67   12.920818\n",
       "3  07-Jan-04  1126.33   23.672431\n",
       "4  08-Jan-04  1131.92   49.630215\n",
       "5  09-Jan-04  1121.86  -88.875539"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp_df = dataset.loc[:, ['Date', 'SP']] # create sp_df \n",
    "sp = sp_df.loc[:, 'SP'].values\n",
    "dr = [(sp[i+1] / sp[i] -1)*10000 for i in range(len(sp)-1)]  # daily return calculation \n",
    "sp_df.drop(sp_df.index[0], inplace=True) # remove first row \n",
    "sp_df['DailyRet'] = dr\n",
    "data_raw = sp_df.iloc[:, 2:3].values\n",
    "sp_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of entries (training set, test set): (607, 65)\n",
      "Original training data shape:\n",
      "(588, 16)\n",
      "(588, 4)\n",
      "New training data shape:\n",
      "(588, 1, 16)\n"
     ]
    }
   ],
   "source": [
    "# Feature Scaling\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler(feature_range = (0, 1))\n",
    "dataset = scaler.fit_transform(data_raw)\n",
    "\n",
    "train_size = 607\n",
    "test_size = len(dataset) - train_size\n",
    "train, test = dataset[0:train_size, :], dataset[train_size:len(dataset), :]\n",
    "print(\"Number of entries (training set, test set): \" +\n",
    "      str((len(train), len(test))))\n",
    "\n",
    "# function to create train and test set\n",
    "\n",
    "\n",
    "def create_dataset(dataset, train_window_size=16, test_window_size=4):\n",
    "    data_X, data_Y = [], []\n",
    "    for i in range(len(dataset) - train_window_size-test_window_size + 1):\n",
    "        a = dataset[i:(i + train_window_size), 0]\n",
    "        b = dataset[(i+train_window_size):(i+train_window_size+test_window_size), 0]\n",
    "        data_X.append(a)\n",
    "        data_Y.append(b)\n",
    "    return(np.array(data_X), np.array(data_Y))\n",
    "\n",
    "\n",
    "train_X, train_y = create_dataset(train)\n",
    "test_X, test_y = create_dataset(test)\n",
    "print(\"Original training data shape:\")\n",
    "print(train_X.shape)\n",
    "print(train_y.shape)\n",
    "\n",
    "# Reshape the input data into appropriate form for Keras.\n",
    "train_X = np.reshape(train_X, (train_X.shape[0], 1, train_X.shape[1]))\n",
    "test_X = np.reshape(test_X, (test_X.shape[0], 1, test_X.shape[1]))\n",
    "print(\"New training data shape:\")\n",
    "print(train_X.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### build LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the Keras libraries and packages\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 1, 50)             13400     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1, 50)             0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4)                 204       \n",
      "=================================================================\n",
      "Total params: 33,804\n",
      "Trainable params: 33,804\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def build_model(window_size = 16):\n",
    "    model = Sequential() \n",
    "    model.add(LSTM(input_shape = (1, window_size), units=50, return_sequences = True, activation='relu')) # add first LSTM layer \n",
    "    model.add(Dropout(0.2))# dropout regulization to avoid overfitting\n",
    "    model.add(LSTM(input_shape=(1, window_size), units=50, return_sequences = False, activation='relu')) # add second LSTM layer \n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(4)) \n",
    "    model.summary()\n",
    "    return(model)\n",
    "\n",
    "model = build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 529 samples, validate on 59 samples\n",
      "Epoch 1/50\n",
      "529/529 [==============================] - 2s 3ms/step - loss: 0.0326 - acc: 0.2533 - val_loss: 0.0254 - val_acc: 0.2373\n",
      "Epoch 2/50\n",
      "529/529 [==============================] - 0s 56us/step - loss: 0.0311 - acc: 0.2703 - val_loss: 0.0254 - val_acc: 0.2542\n",
      "Epoch 3/50\n",
      "529/529 [==============================] - 0s 41us/step - loss: 0.0310 - acc: 0.2684 - val_loss: 0.0255 - val_acc: 0.1864\n",
      "Epoch 4/50\n",
      "529/529 [==============================] - 0s 47us/step - loss: 0.0311 - acc: 0.2457 - val_loss: 0.0255 - val_acc: 0.2034\n",
      "Epoch 5/50\n",
      "529/529 [==============================] - 0s 43us/step - loss: 0.0312 - acc: 0.2250 - val_loss: 0.0255 - val_acc: 0.2542\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-2.03273888e+01, -2.10666771e+01, -1.48870897e+01,\n",
       "        -2.40379658e+01],\n",
       "       [-2.17021656e+01, -2.11784992e+01, -1.57304268e+01,\n",
       "        -1.97140121e+01],\n",
       "       [-1.61526127e+01, -1.77189140e+01, -1.02468071e+01,\n",
       "        -1.62622967e+01],\n",
       "       [-1.89458942e+01, -1.70219612e+01, -1.04210567e+01,\n",
       "        -1.90790691e+01],\n",
       "       [-5.57877588e+00, -1.44440901e+00,  2.89283562e+00,\n",
       "        -6.01809311e+00],\n",
       "       [-2.59391093e+00, -1.96655321e+00,  1.84003508e+00,\n",
       "        -3.07197237e+00],\n",
       "       [-2.10863304e+00, -3.14264989e+00,  6.60281801e+00,\n",
       "        -2.48420358e+00],\n",
       "       [-1.70222366e+00, -2.70381093e-01,  5.34510612e+00,\n",
       "        -1.84445798e+00],\n",
       "       [ 4.66416693e+00,  9.58082294e+00,  1.21063986e+01,\n",
       "         4.45232534e+00],\n",
       "       [ 5.31135464e+00,  3.58345222e+00,  1.01116104e+01,\n",
       "        -6.08051002e-01],\n",
       "       [-9.19531441e+00, -9.78908634e+00, -3.83185172e+00,\n",
       "        -1.35043001e+01],\n",
       "       [-6.88628817e+00, -8.25740433e+00, -9.43759322e-01,\n",
       "        -7.41397238e+00],\n",
       "       [-8.10801315e+00, -6.82023525e+00, -2.12029576e+00,\n",
       "        -9.11403179e+00],\n",
       "       [-1.04136028e+01, -1.15334072e+01, -3.95473170e+00,\n",
       "        -1.25929012e+01],\n",
       "       [-9.84597301e+00, -9.45731354e+00, -1.25531018e+00,\n",
       "        -1.11218863e+01],\n",
       "       [-6.85267925e+00, -3.57338333e+00, -7.98338830e-01,\n",
       "        -8.85417271e+00],\n",
       "       [-5.37485218e+00, -7.50118685e+00,  1.01252198e+00,\n",
       "        -8.69745827e+00],\n",
       "       [-9.68776035e+00, -6.79872894e+00, -2.14231324e+00,\n",
       "        -9.90806675e+00],\n",
       "       [-4.61088324e+00,  5.43269873e-01,  1.60640168e+00,\n",
       "        -1.77048755e+00],\n",
       "       [-6.70054150e+00, -6.30738783e+00,  1.05382276e+00,\n",
       "        -8.18142414e+00],\n",
       "       [-8.49761200e+00, -4.43470716e+00,  4.31470126e-01,\n",
       "        -8.75319099e+00],\n",
       "       [-3.11172771e+00, -2.12034321e+00,  1.95494962e+00,\n",
       "        -5.17833471e+00],\n",
       "       [-1.13922071e+01, -9.60693073e+00, -5.49347591e+00,\n",
       "        -1.15167036e+01],\n",
       "       [-1.35973635e+01, -1.50547543e+01, -8.08510399e+00,\n",
       "        -1.64397202e+01],\n",
       "       [-1.34230652e+01, -1.30617847e+01, -6.95621634e+00,\n",
       "        -1.25759010e+01],\n",
       "       [-7.13166714e+00, -7.17166042e+00, -8.03308249e-01,\n",
       "        -7.20047808e+00],\n",
       "       [-1.27352304e+01, -1.13478508e+01, -6.03455877e+00,\n",
       "        -1.54274359e+01],\n",
       "       [-8.01220322e+00, -7.86741257e+00, -6.57697499e-01,\n",
       "        -9.21527481e+00],\n",
       "       [-2.80606174e+00, -3.13286567e+00,  3.35392022e+00,\n",
       "        -3.48918867e+00],\n",
       "       [-1.10959244e+00, -2.07337165e+00,  5.19670200e+00,\n",
       "        -2.70119309e+00],\n",
       "       [-1.88297689e+00, -1.81887388e+00,  6.01903152e+00,\n",
       "        -3.70755720e+00],\n",
       "       [ 1.65654510e-01,  5.73243475e+00,  6.59582758e+00,\n",
       "        -4.66339737e-01],\n",
       "       [ 4.30018759e+00,  1.91075993e+00,  1.01976595e+01,\n",
       "        -4.94589983e-03],\n",
       "       [-6.13810778e+00, -7.58415651e+00,  4.67635036e-01,\n",
       "        -9.23272705e+00],\n",
       "       [-5.46802235e+00, -2.17128563e+00,  1.31944823e+00,\n",
       "        -5.07766247e+00],\n",
       "       [-1.59542894e+00,  7.82975852e-02,  4.99722433e+00,\n",
       "        -3.87368751e+00],\n",
       "       [-3.04334497e+00, -2.83623481e+00,  3.74804878e+00,\n",
       "        -4.79925728e+00],\n",
       "       [-2.26289868e+00, -1.87989771e+00,  4.48939371e+00,\n",
       "        -2.40348053e+00],\n",
       "       [-2.43972850e+00,  1.76938152e+00,  5.41549826e+00,\n",
       "        -9.79092002e-01],\n",
       "       [ 2.80701232e+00,  4.40686369e+00,  9.62670135e+00,\n",
       "         2.96880096e-01],\n",
       "       [-1.17584717e+00, -1.69432962e+00,  4.58405018e+00,\n",
       "        -3.02729535e+00],\n",
       "       [-2.81935310e+00, -2.92997575e+00,  3.80728936e+00,\n",
       "        -4.89757538e+00],\n",
       "       [-5.42927790e+00, -5.52877283e+00, -5.18827617e-01,\n",
       "        -9.28796101e+00],\n",
       "       [-8.42908669e+00, -9.16199017e+00, -2.88060284e+00,\n",
       "        -1.09382792e+01],\n",
       "       [-8.17018986e+00, -9.79193974e+00, -2.48277688e+00,\n",
       "        -1.01089592e+01],\n",
       "       [-8.47049427e+00, -8.62222767e+00, -1.46433425e+00,\n",
       "        -9.60707283e+00]], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compile, fit and evaluate\n",
    "def fit_model(model, train_X, train_y):\n",
    "    model.compile(loss='mean_squared_error', optimizer='rmsprop', metrics=['accuracy']) \n",
    "    es = EarlyStopping(monitor='val_loss', min_delta=0, patience=3, mode='auto', baseline=None)\n",
    "    model.fit( train_X, train_y, batch_size=100, epochs=50, validation_split=0.1, callbacks=[es], verbose=1)\n",
    "    return model\n",
    "    \n",
    "model_fit = fit_model(model, train_X, train_y)    \n",
    "\n",
    "pred = scaler.inverse_transform(model.predict(test_X))\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [4, 588]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-7edd8298dc12>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;32mreturn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mrmse_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_predict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpredict_and_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_fit\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_X\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;31m# rmse_test, test_predict = predict_and_score(model_fit, test_X, test_y)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-15-7edd8298dc12>\u001b[0m in \u001b[0;36mpredict_and_score\u001b[1;34m(model, X, Y)\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0morig_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;31m# Calculate RMSE.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmean_squared_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0morig_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[1;32mreturn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\python35\\lib\\site-packages\\sklearn\\metrics\\regression.py\u001b[0m in \u001b[0;36mmean_squared_error\u001b[1;34m(y_true, y_pred, sample_weight, multioutput)\u001b[0m\n\u001b[0;32m    237\u001b[0m     \"\"\"\n\u001b[0;32m    238\u001b[0m     y_type, y_true, y_pred, multioutput = _check_reg_targets(\n\u001b[1;32m--> 239\u001b[1;33m         y_true, y_pred, multioutput)\n\u001b[0m\u001b[0;32m    240\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    241\u001b[0m     output_errors = np.average((y_true - y_pred) ** 2, axis=0,\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\python35\\lib\\site-packages\\sklearn\\metrics\\regression.py\u001b[0m in \u001b[0;36m_check_reg_targets\u001b[1;34m(y_true, y_pred, multioutput)\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m     \"\"\"\n\u001b[1;32m---> 75\u001b[1;33m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     76\u001b[0m     \u001b[0my_true\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\python35\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    233\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    234\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[1;32m--> 235\u001b[1;33m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[0;32m    236\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    237\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [4, 588]"
     ]
    }
   ],
   "source": [
    "def predict_and_score(model, X, Y):\n",
    "    # Make predictions on the original scale of the data.\n",
    "    pred = scaler.inverse_transform(model.predict(X))\n",
    "    # Prepare Y data to also be on the original scale for interpretability.\n",
    "    orig_data = scaler.inverse_transform((Y))\n",
    "    # Calculate RMSE.\n",
    "    score = math.sqrt(mean_squared_error(orig_data[0], pred[:, 0]))\n",
    "    return(score, pred)\n",
    "\n",
    "rmse_train, train_predict = predict_and_score(model_fit, train_X, train_y)\n",
    "# rmse_test, test_predict = predict_and_score(model_fit, test_X, test_y)\n",
    "\n",
    "# print(\"Training data score: %.2f RMSE\" % rmse_train)\n",
    "# print(\"Test data score: %.2f RMSE\" % rmse_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

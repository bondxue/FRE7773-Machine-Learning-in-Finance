{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 5\n",
    "#### Assigned: 2019-04-25\n",
    "#### Due EOD: 2019-05-02\n",
    "\n",
    "Based on Lecture 12\n",
    "+ The student fills in the <...> fields.  \n",
    "+ The student can create as many new cells as necessary in the solution sections."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Make sure you have activated the correct python envorinment**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Name:  Mengheng Xue\n",
    "#### NetID: mx586"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1 (20 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A CNN has the following structure:  \n",
    "\n",
    "Conv2D_Layer -> Pooling_Layer -> Flattening_Layer -> Dense_Layer\n",
    "\n",
    "+ input shape (size of the image): $M_1 \\times M_2$\n",
    "+ conv2d kernel with bias\n",
    "+ conv2d kernel shape: $K_1 \\times K_2$  \n",
    "+ conv2d padding: same  \n",
    "+ conv2d stride in both dimensions: 1  \n",
    "+ conv2d filters (number of kernels): $F$\n",
    "+ pooling layer size: $P_1 \\times P_2$ (assume $P_{1,2}$ is a divisor of $M_{1,2}$) \n",
    "+ pooling padding: same\n",
    "+ pooling stride in both dimensions: 1\n",
    "+ flattening layer  \n",
    "+ dense layer with bias\n",
    "+ dense layer units (number of nodes): $H$\n",
    "\n",
    "Write down the expression that gives the total number of parameters to be fitted $Q$ in terms of the above values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<...>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2 (80 points) \n",
    "\n",
    "Use LSTM to analyze S&P 500 returns over the period 2004-2006.\n",
    "\n",
    "The data file \"stock-treasury-2004_2006.csv\", to be found in the \"Data\" folder, contains the following:  \n",
    "+ TREAS_3M: the yield of the 3-month treasury note in percent (i.e 2.1 means 2.1%)\n",
    "+ Adjusted close price of ten major stocks: GM, F, UTX, CAT, MRK, PFE, IBM, MSFT, C, XOM\n",
    "+ SP: The S&P 500 equity index level at the close of the trading day  \n",
    "\n",
    "**Do the following:**  \n",
    "\n",
    "Use the pandas read_csv function to read the Date and SP columns in a data frame called \"sp_df\".  \n",
    "Rename the \"SP\" column into \"ClosePx\" in the same read_csv call.  \n",
    "Compute the close-to-close index returns as:  $r_t = P_{t+1}/P_t - 1$ and add them as a new column \"DailyRet\".  \n",
    "It is recommended to express all daily returns in basis points (10,000 bps = 100% = 1)\n",
    "\n",
    "We want to train an RNN that looks back $M$ days and forecasts forward $N$ days.  \n",
    "Therefore the RNN will use return sequences of size $M$, and targets of size $N$.  \n",
    "\n",
    "Reformat the return data suitable for RNN processing as follows.  \n",
    "From the \"DailyRet\" column of \"sp_df\", create a data input matrix $X$ containing rows as below:    \n",
    "$$r_0, r_1, r_2, \\ldots, r_{M-1}$$  \n",
    "$$r_1, r_2, r_3, \\ldots, r_{M}$$  \n",
    "$$r_2, r_3, r_4, \\ldots, r_{M+1}$$  \n",
    "$$\\ldots$$\n",
    "From the \"DailyRet\" column of \"sp_df\", create also a target matrix $y$ containing rows as below:\n",
    "$$ r_{M}, r_{M+1}, \\ldots, r_{M+N-1}$$\n",
    "$$ r_{M+1}, r_{M+2}, \\ldots, r_{M+N}$$\n",
    "$$ r_{M+2}, r_{M+3}, \\ldots, r_{M+N+1}$$\n",
    "$$\\ldots$$\n",
    "\n",
    "Set $M=16$ and $N=4$.  \n",
    "Build an RNN with two LSTM cells and train it on the first 607 sequences.  \n",
    "This means that the training set contains returns with the latest date of 2016-05-31.    \n",
    "Use the remaining returns for out-of-sample testing.  \n",
    "This is a regression task, so train the network using mean_squared_error loss.  \n",
    "When connecting the two LSTMs, make sure you set the parameter return_sequences=True on the first LSTM, \n",
    "so that the second can see the sequences.\n",
    "\n",
    "Compute the out-of-sample actual and predicted 2-day, 3-day, ..., N-day return, by summing 1-day forward returns up to this horizon.  \n",
    "N-day return is the return from today's close to the close of the N-th day forward from today.  \n",
    "Calculate and report the RMSE and the correlation between actual and predicted 1-day, 2-day, ..., N-day returns.  \n",
    "Plot the actual and predicted returns in the out-of-sample part.  \n",
    "What do you conclude regarding the quality of the forecasts?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>TREAS_3M</th>\n",
       "      <th>GM</th>\n",
       "      <th>F</th>\n",
       "      <th>UTX</th>\n",
       "      <th>CAT</th>\n",
       "      <th>MRK</th>\n",
       "      <th>PFE</th>\n",
       "      <th>IBM</th>\n",
       "      <th>MSFT</th>\n",
       "      <th>C</th>\n",
       "      <th>XOM</th>\n",
       "      <th>SP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>02-Jan-04</td>\n",
       "      <td>0.91</td>\n",
       "      <td>46.72</td>\n",
       "      <td>14.55</td>\n",
       "      <td>45.13</td>\n",
       "      <td>39.35</td>\n",
       "      <td>41.76</td>\n",
       "      <td>32.85</td>\n",
       "      <td>89.10</td>\n",
       "      <td>24.00</td>\n",
       "      <td>44.17</td>\n",
       "      <td>38.31</td>\n",
       "      <td>1108.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>05-Jan-04</td>\n",
       "      <td>0.90</td>\n",
       "      <td>47.55</td>\n",
       "      <td>15.02</td>\n",
       "      <td>45.40</td>\n",
       "      <td>40.42</td>\n",
       "      <td>42.60</td>\n",
       "      <td>33.73</td>\n",
       "      <td>90.56</td>\n",
       "      <td>24.60</td>\n",
       "      <td>44.88</td>\n",
       "      <td>39.20</td>\n",
       "      <td>1122.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>06-Jan-04</td>\n",
       "      <td>0.90</td>\n",
       "      <td>47.26</td>\n",
       "      <td>14.97</td>\n",
       "      <td>45.29</td>\n",
       "      <td>39.70</td>\n",
       "      <td>42.40</td>\n",
       "      <td>33.71</td>\n",
       "      <td>90.57</td>\n",
       "      <td>24.69</td>\n",
       "      <td>44.93</td>\n",
       "      <td>38.94</td>\n",
       "      <td>1123.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>07-Jan-04</td>\n",
       "      <td>0.89</td>\n",
       "      <td>47.91</td>\n",
       "      <td>15.38</td>\n",
       "      <td>45.43</td>\n",
       "      <td>39.27</td>\n",
       "      <td>42.45</td>\n",
       "      <td>34.00</td>\n",
       "      <td>90.30</td>\n",
       "      <td>24.66</td>\n",
       "      <td>44.99</td>\n",
       "      <td>38.65</td>\n",
       "      <td>1126.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>08-Jan-04</td>\n",
       "      <td>0.86</td>\n",
       "      <td>47.90</td>\n",
       "      <td>15.48</td>\n",
       "      <td>45.38</td>\n",
       "      <td>38.97</td>\n",
       "      <td>42.67</td>\n",
       "      <td>33.68</td>\n",
       "      <td>90.55</td>\n",
       "      <td>24.62</td>\n",
       "      <td>45.18</td>\n",
       "      <td>38.56</td>\n",
       "      <td>1131.92</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date  TREAS_3M     GM      F    UTX    CAT    MRK    PFE    IBM  \\\n",
       "0  02-Jan-04      0.91  46.72  14.55  45.13  39.35  41.76  32.85  89.10   \n",
       "1  05-Jan-04      0.90  47.55  15.02  45.40  40.42  42.60  33.73  90.56   \n",
       "2  06-Jan-04      0.90  47.26  14.97  45.29  39.70  42.40  33.71  90.57   \n",
       "3  07-Jan-04      0.89  47.91  15.38  45.43  39.27  42.45  34.00  90.30   \n",
       "4  08-Jan-04      0.86  47.90  15.48  45.38  38.97  42.67  33.68  90.55   \n",
       "\n",
       "    MSFT      C    XOM       SP  \n",
       "0  24.00  44.17  38.31  1108.48  \n",
       "1  24.60  44.88  39.20  1122.22  \n",
       "2  24.69  44.93  38.94  1123.67  \n",
       "3  24.66  44.99  38.65  1126.33  \n",
       "4  24.62  45.18  38.56  1131.92  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import libraries \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# import the dataset  \n",
    "dataset = pd.read_csv('stock-treasury-2004_2006.csv')\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>SP</th>\n",
       "      <th>DailyRet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>05-Jan-04</td>\n",
       "      <td>1122.22</td>\n",
       "      <td>123.953522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>06-Jan-04</td>\n",
       "      <td>1123.67</td>\n",
       "      <td>12.920818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>07-Jan-04</td>\n",
       "      <td>1126.33</td>\n",
       "      <td>23.672431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>08-Jan-04</td>\n",
       "      <td>1131.92</td>\n",
       "      <td>49.630215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>09-Jan-04</td>\n",
       "      <td>1121.86</td>\n",
       "      <td>-88.875539</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date       SP    DailyRet\n",
       "1  05-Jan-04  1122.22  123.953522\n",
       "2  06-Jan-04  1123.67   12.920818\n",
       "3  07-Jan-04  1126.33   23.672431\n",
       "4  08-Jan-04  1131.92   49.630215\n",
       "5  09-Jan-04  1121.86  -88.875539"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp_df = dataset.loc[:, ['Date', 'SP']] # create sp_df \n",
    "sp = sp_df.loc[:, 'SP'].values\n",
    "dr = [(sp[i+1] / sp[i] -1)*10000 for i in range(len(sp)-1)]  # daily return calculation \n",
    "sp_df.drop(sp_df.index[0], inplace=True) # remove first row \n",
    "sp_df['DailyRet'] = dr\n",
    "dr_samples = sp_df.iloc[:, 2:3].values\n",
    "sp_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Feature Scaling\n",
    "# from sklearn.preprocessing import MinMaxScaler # use normalisation instead of standardisation \n",
    "# sc = MinMaxScaler(feature_range = (0, 1)) # \n",
    "# training_set_scaled = sc.fit_transform(training_set) # x_norm = (x-min(x))/(max(x)-min(x))\n",
    "\n",
    "X_train =  []\n",
    "y_train = []\n",
    "training_size = 16\n",
    "test_size = 4\n",
    "training_sample_no = 607\n",
    "training_set = dr_samples[:training_sample_no]\n",
    "test_set = dr_samples[training_sample_no:]\n",
    "\n",
    "for i in range(training_size, len(training_set)):\n",
    "    X_train.append(training_set[i-training_size:i, 0])\n",
    "    y_train.append(training_set[i:i+test_size, 0])\n",
    "X_train, y_train = np.array(X_train), np.array(y_train)\n",
    "\n",
    "X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1)) # reshaping to 3D \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### build RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Importing the Keras libraries and packages\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking target: expected dense_3 to have shape (4,) but got array with shape (1,)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-50-971b45ed3c31>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;31m# Fitting the RNN to the Training set 将我们的模型连接traning set\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;31m# batch_size: update every 32 stock prices each epoch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m \u001b[0mregressor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\python35\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m    948\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    949\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 950\u001b[1;33m             batch_size=batch_size)\n\u001b[0m\u001b[0;32m    951\u001b[0m         \u001b[1;31m# Prepare validation data.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    952\u001b[0m         \u001b[0mdo_validation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\python35\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[0;32m    785\u001b[0m                 \u001b[0mfeed_output_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    786\u001b[0m                 \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# Don't enforce the batch size.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 787\u001b[1;33m                 exception_prefix='target')\n\u001b[0m\u001b[0;32m    788\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    789\u001b[0m             \u001b[1;31m# Generate sample-wise weight values given the `sample_weight` and\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\python35\\lib\\site-packages\\keras\\engine\\training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[1;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[0;32m    135\u001b[0m                             \u001b[1;34m': expected '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' to have shape '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    136\u001b[0m                             \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' but got array with shape '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 137\u001b[1;33m                             str(data_shape))\n\u001b[0m\u001b[0;32m    138\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    139\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Error when checking target: expected dense_3 to have shape (4,) but got array with shape (1,)"
     ]
    }
   ],
   "source": [
    "# Initialising the RNN\n",
    "regressor = Sequential()\n",
    "\n",
    "# Adding the first LSTM layer and some Dropout regularisation\n",
    "regressor.add(LSTM(units = 50, return_sequences = True, input_shape = (X_train.shape[1], 1)))\n",
    "regressor.add(Dropout(0.2))# dropout regulization to avoid overfitting \n",
    "\n",
    "# Adding a second LSTM layer and some Dropout regularisation\n",
    "regressor.add(LSTM(units = 50)) # return_sequences = false \n",
    "regressor.add(Dropout(0.2))\n",
    "\n",
    "# Adding the output layer\n",
    "regressor.add(Dense(units = 1)) # predit one value \n",
    "\n",
    "# Compiling the RNN\n",
    "# optimizer: such as RMSprop/ adam \n",
    "# loss: loss function MSE\n",
    "regressor.compile(optimizer = 'adam', loss = 'mean_squared_error')\n",
    "\n",
    "# Fitting the RNN to the Training set 将我们的模型连接traning set \n",
    "# batch_size: update every 32 stock prices each epoch\n",
    "regressor.fit(X_train, y_train, epochs = 100, batch_size = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

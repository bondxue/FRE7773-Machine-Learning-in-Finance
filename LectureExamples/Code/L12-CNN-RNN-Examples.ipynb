{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN and RNN Examples\n",
    "**Make sure you have activated the correct python envorinment**\n",
    "\n",
    "+ Using the keras Sequential API and MNIST data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "np.random.seed(42)\n",
    "\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, SimpleRNN, LSTM\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data\n",
    "\n",
    "MNIST is a dataset of 60,000 28x28 grayscale images of handwritten digits, along with a test set of 10,000 images.\n",
    "\n",
    "Load the MNIST data using keras. The first time the data are downloaded and cached.  \n",
    "Subsequent times the data are loaded from the cache."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the date and split into training/testing sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert the target values vector to binary class matrix\n",
    "y_train is a vector of size 60,000.  \n",
    "It gets mapped to a 60,000 x 10 matrix of 0s and 1s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Targets before: \n",
      "[5 0 4 1 9]\n",
      "Targets after: \n",
      "[[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "n_classes = 10\n",
    "\n",
    "print(\"Targets before: \\n{}\".format(y_train[:5]))\n",
    "ybm_train = to_categorical(y_train, n_classes)\n",
    "ybm_test = to_categorical(y_test, n_classes)\n",
    "print(\"Targets after: \\n{}\".format(ybm_train[:5]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reshape and normalize the input data\n",
    "The inputs are fed to the CNN as 2D images with dimensions image_size x image_size (28x28).  \n",
    "The third singleton dimension is the channel, which in our case is the grayscale value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = x_train.shape[1]\n",
    "xcnn_train = np.reshape(x_train,[-1, image_size, image_size, 1])\n",
    "xcnn_test = np.reshape(x_test,[-1, image_size, image_size, 1])\n",
    "xcnn_train = xcnn_train.astype('float32') / 255\n",
    "xcnn_test = xcnn_test.astype('float32') / 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct the CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_2 (Conv2D)            (None, 28, 28, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 6272)              0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 6272)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                62730     \n",
      "=================================================================\n",
      "Total params: 63,050\n",
      "Trainable params: 63,050\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# parameters\n",
    "cnn_input_shape = (image_size, image_size, 1)\n",
    "cnn1_layers = 1\n",
    "kernel_size = 3\n",
    "n_filters = 32\n",
    "cnn1_drop_rate = 0.4\n",
    "\n",
    "cnn1 = Sequential()\n",
    "cnn1.add(Conv2D(input_shape=cnn_input_shape, filters=n_filters, kernel_size=kernel_size,  padding='same', activation='relu'))\n",
    "cnn1.add(MaxPooling2D())\n",
    "for i in range(cnn1_layers - 1):\n",
    "    cnn1.add(Conv2D(filters=n_filters, kernel_size=kernel_size,  padding='same', activation='relu'))\n",
    "    cnn1.add(Dropout(cnn1_drop_rate))\n",
    "    cnn1.add(MaxPooling2D())\n",
    "cnn1.add(Flatten())\n",
    "cnn1.add(Dropout(cnn1_drop_rate))\n",
    "cnn1.add(Dense(n_classes, activation='softmax'))\n",
    "cnn1.summary()\n",
    "\n",
    "# the number of parameters is: n_classes x (input_dim + 1)\n",
    "# each node has its own bias (therefore +1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile and fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/10\n",
      "54000/54000 [==============================] - 23s 434us/step - loss: 0.7349 - acc: 0.8148 - val_loss: 0.2474 - val_acc: 0.9298\n",
      "Epoch 2/10\n",
      "54000/54000 [==============================] - 22s 405us/step - loss: 0.2805 - acc: 0.9183 - val_loss: 0.1721 - val_acc: 0.9537\n",
      "Epoch 3/10\n",
      "54000/54000 [==============================] - 22s 410us/step - loss: 0.2073 - acc: 0.9399 - val_loss: 0.1310 - val_acc: 0.9645\n",
      "Epoch 4/10\n",
      "54000/54000 [==============================] - 21s 398us/step - loss: 0.1642 - acc: 0.9528 - val_loss: 0.1081 - val_acc: 0.9712\n",
      "Epoch 5/10\n",
      "54000/54000 [==============================] - 21s 396us/step - loss: 0.1387 - acc: 0.9599 - val_loss: 0.0931 - val_acc: 0.9772\n",
      "Epoch 6/10\n",
      "54000/54000 [==============================] - 21s 397us/step - loss: 0.1216 - acc: 0.9649 - val_loss: 0.0854 - val_acc: 0.9778\n",
      "Epoch 7/10\n",
      "54000/54000 [==============================] - 21s 395us/step - loss: 0.1109 - acc: 0.9671 - val_loss: 0.0779 - val_acc: 0.9800\n",
      "Epoch 8/10\n",
      "54000/54000 [==============================] - 23s 423us/step - loss: 0.1040 - acc: 0.9697 - val_loss: 0.0739 - val_acc: 0.9798\n",
      "Epoch 9/10\n",
      "54000/54000 [==============================] - 22s 406us/step - loss: 0.0976 - acc: 0.9716 - val_loss: 0.0705 - val_acc: 0.9813\n",
      "Epoch 10/10\n",
      "54000/54000 [==============================] - 23s 417us/step - loss: 0.0921 - acc: 0.9728 - val_loss: 0.0668 - val_acc: 0.9833\n",
      "1-Layer CNN\n",
      "------------------------\n",
      "Test loss score: 0.0700\n",
      "Test accuracy:   0.9787\n"
     ]
    }
   ],
   "source": [
    "# compile, fit and evaluate\n",
    "cnn1.compile(optimizer='nadam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "cnn1_batch_size = 1000\n",
    "cnn1_epochs = 10\n",
    "cnn1_val_split = 0.1 \n",
    "# create an early stopping callback\n",
    "# cnn1_es = EarlyStopping(monitor='val_loss', min_delta=0, patience=3, mode='auto', baseline=None, restore_best_weights=False)\n",
    "\n",
    "cnn1_es = EarlyStopping(monitor='val_loss', min_delta=0, patience=3, mode='auto', baseline=None)\n",
    "cnn1_hist = cnn1.fit(xcnn_train, ybm_train, batch_size=cnn1_batch_size, epochs=cnn1_epochs, validation_split=cnn1_val_split, callbacks=[cnn1_es], verbose=1)\n",
    "cnn1_val_score = cnn1.evaluate(xcnn_test, ybm_test, verbose=0)\n",
    "\n",
    "print('{}-Layer CNN'.format(cnn1_layers))\n",
    "print('------------------------')\n",
    "print('Test loss score: {0:.4f}'.format(cnn1_val_score[0]))\n",
    "print('Test accuracy:   {0:.4f}'.format(cnn1_val_score[1]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN predictions and true values\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[7, 2, 1, 0, 4, 1, 4, 9, 6, 9, 0, 6, 9, 0, 1, 5, 9, 7, 8, 4]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[7, 2, 1, 0, 4, 1, 4, 9, 5, 9, 0, 6, 9, 0, 1, 5, 9, 7, 3, 4]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cnn1_pred = cnn1.predict(xcnn_test[:20])\n",
    "cnn1_ypred = np.argmax(cnn1_pred, axis=1)\n",
    "\n",
    "print('CNN predictions and true values')\n",
    "display(cnn1_ypred.tolist())\n",
    "display(y_test[:20].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predited values: [7 8 4]\n",
      "True values: [7 3 4]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot a few digits and print the true values\n",
    "idigits = [17, 18, 19]\n",
    "\n",
    "fig = plt.figure(figsize=(12, 6))\n",
    "for i in range(len(idigits)):\n",
    "    ax = fig.add_subplot(1, len(idigits), i + 1)\n",
    "    ax.imshow(x_test[idigits[i]], cmap = plt.cm.binary, interpolation=\"nearest\")\n",
    "    ax.axis(\"off\")\n",
    "print('Predited values: {}'.format(cnn1_ypred[idigits]))\n",
    "print('True values: {}'.format(y_test[idigits]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reshape and normalize the input data\n",
    "The inputs are fed to the RNN as 2D images with dimensions image_size x image_size (28x28).  \n",
    "The first dimension is the 'time'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "xrnn_train = np.reshape(x_train,[-1, image_size, image_size])\n",
    "xrnn_test = np.reshape(x_test,[-1, image_size, image_size])\n",
    "xrnn_train = xrnn_train.astype('float32') / 255\n",
    "xrnn_test = xrnn_test.astype('float32') / 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct a SimpleRNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "simple_rnn_2 (SimpleRNN)     (None, 256)               72960     \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 75,530\n",
      "Trainable params: 75,530\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# parameters\n",
    "rnn_input_shape = (image_size, image_size)\n",
    "rnn1_layers = 1\n",
    "n_units = 256\n",
    "rnn1_drop_rate = 0.4\n",
    "\n",
    "rnn1 = Sequential()\n",
    "rnn1.add(SimpleRNN(input_shape=rnn_input_shape, units=n_units, activation='relu'))\n",
    "rnn1.add(Dropout(rnn1_drop_rate))\n",
    "for i in range(rnn1_layers - 1):\n",
    "    rnn1.add(SimpleRNN(input_shape=rnn_input_shape, units=n_units, activation='relu'))\n",
    "    rnn1.add(Dropout(rnn1_drop_rate))\n",
    "rnn1.add(Dense(n_classes, activation='softmax'))\n",
    "rnn1.summary()\n",
    "\n",
    "# the number of parameters is: n_classes x (input_dim + 1)\n",
    "# each node has its own bias (therefore +1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile and fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/10\n",
      "54000/54000 [==============================] - 13s 247us/step - loss: 1.6807 - acc: 0.4014 - val_loss: 0.9750 - val_acc: 0.6787\n",
      "Epoch 2/10\n",
      "54000/54000 [==============================] - 13s 234us/step - loss: 0.8152 - acc: 0.7201 - val_loss: 0.3393 - val_acc: 0.8835\n",
      "Epoch 3/10\n",
      "54000/54000 [==============================] - 13s 246us/step - loss: 0.3779 - acc: 0.8804 - val_loss: 0.1826 - val_acc: 0.9437\n",
      "Epoch 4/10\n",
      "54000/54000 [==============================] - 13s 236us/step - loss: 0.2379 - acc: 0.9308 - val_loss: 0.1067 - val_acc: 0.9717\n",
      "Epoch 5/10\n",
      "54000/54000 [==============================] - 13s 239us/step - loss: 0.1750 - acc: 0.9497 - val_loss: 0.1406 - val_acc: 0.9620\n",
      "Epoch 6/10\n",
      "54000/54000 [==============================] - 14s 260us/step - loss: 0.1422 - acc: 0.9604 - val_loss: 2.5742 - val_acc: 0.4935\n",
      "Epoch 7/10\n",
      "54000/54000 [==============================] - 13s 240us/step - loss: 1.5309 - acc: 0.4893 - val_loss: 0.8065 - val_acc: 0.7307\n",
      "1-Layer SimpleRNN\n",
      "------------------------\n",
      "Test loss score: 0.8805\n",
      "Test accuracy:   0.6969\n"
     ]
    }
   ],
   "source": [
    "# compile, fit and evaluate\n",
    "rnn1.compile(optimizer='nadam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "rnn1_batch_size = 1000\n",
    "rnn1_epochs = 10\n",
    "rnn1_val_split = 0.1 \n",
    "# create an early stopping callback\n",
    "# rnn1_es = EarlyStopping(monitor='val_loss', min_delta=0, patience=3, mode='auto', baseline=None, restore_best_weights=False)\n",
    "\n",
    "rnn1_es = EarlyStopping(monitor='val_loss', min_delta=0, patience=3, mode='auto', baseline=None)\n",
    "rnn1_hist = rnn1.fit(xrnn_train, ybm_train, batch_size=rnn1_batch_size, epochs=rnn1_epochs, validation_split=rnn1_val_split, callbacks=[rnn1_es], verbose=1)\n",
    "rnn1_val_score = rnn1.evaluate(xrnn_test, ybm_test, verbose=0)\n",
    "\n",
    "print('{}-Layer SimpleRNN'.format(rnn1_layers))\n",
    "print('------------------------')\n",
    "print('Test loss score: {0:.4f}'.format(rnn1_val_score[0]))\n",
    "print('Test accuracy:   {0:.4f}'.format(rnn1_val_score[1]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LSTM is a drop-in replacement for SimpleRNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 256)               291840    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 294,410\n",
      "Trainable params: 294,410\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# parameters\n",
    "rnn_input_shape = (image_size, image_size)\n",
    "rnn2_layers = 1\n",
    "n_units = 256\n",
    "rnn2_drop_rate = 0.4\n",
    "\n",
    "rnn2 = Sequential()\n",
    "rnn2.add(LSTM(input_shape=rnn_input_shape, units=n_units, activation='relu'))\n",
    "rnn2.add(Dropout(rnn2_drop_rate))\n",
    "for i in range(rnn2_layers - 1):\n",
    "    rnn2.add(SimpleRNN(input_shape=rnn_input_shape, units=n_units, activation='relu'))\n",
    "    rnn2.add(Dropout(rnn2_drop_rate))\n",
    "rnn2.add(Dense(n_classes, activation='softmax'))\n",
    "rnn2.summary()\n",
    "\n",
    "# the number of parameters is: n_classes x (input_dim + 1)\n",
    "# each node has its own bias (therefore +1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/10\n",
      "54000/54000 [==============================] - 70s 1ms/step - loss: 2.1541 - acc: 0.3024 - val_loss: 1.7647 - val_acc: 0.3960\n",
      "Epoch 2/10\n",
      "54000/54000 [==============================] - 65s 1ms/step - loss: 1.5826 - acc: 0.4680 - val_loss: 0.8452 - val_acc: 0.7092\n",
      "Epoch 3/10\n",
      "54000/54000 [==============================] - 69s 1ms/step - loss: 1.0846 - acc: 0.6247 - val_loss: 0.5174 - val_acc: 0.8167\n",
      "Epoch 4/10\n",
      "54000/54000 [==============================] - 70s 1ms/step - loss: 0.4640 - acc: 0.8443 - val_loss: 0.3413 - val_acc: 0.8755\n",
      "Epoch 5/10\n",
      "54000/54000 [==============================] - 66s 1ms/step - loss: 0.2889 - acc: 0.9078 - val_loss: 0.1430 - val_acc: 0.9540\n",
      "Epoch 6/10\n",
      "54000/54000 [==============================] - 69s 1ms/step - loss: 0.1937 - acc: 0.9393 - val_loss: 0.1139 - val_acc: 0.9623\n",
      "Epoch 7/10\n",
      "54000/54000 [==============================] - 67s 1ms/step - loss: 0.1586 - acc: 0.9517 - val_loss: 0.0866 - val_acc: 0.9748\n",
      "Epoch 8/10\n",
      "54000/54000 [==============================] - 66s 1ms/step - loss: 0.1166 - acc: 0.9648 - val_loss: 0.0714 - val_acc: 0.9792\n",
      "Epoch 9/10\n",
      "54000/54000 [==============================] - 73s 1ms/step - loss: 0.0886 - acc: 0.9741 - val_loss: 0.0843 - val_acc: 0.9752\n",
      "Epoch 10/10\n",
      "54000/54000 [==============================] - 64s 1ms/step - loss: 0.1051 - acc: 0.9686 - val_loss: 0.0564 - val_acc: 0.9840\n",
      "1-Layer LSTM\n",
      "------------------------\n",
      "Test loss score: 0.0770\n",
      "Test accuracy:   0.9775\n"
     ]
    }
   ],
   "source": [
    "# compile, fit and evaluate\n",
    "rnn2.compile(optimizer='nadam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "rnn2_batch_size = 1000\n",
    "rnn2_epochs = 10\n",
    "rnn2_val_split = 0.1 \n",
    "# create an early stopping callback\n",
    "rnn2_es = EarlyStopping(monitor='val_loss', min_delta=0, patience=3, mode='auto', baseline=None, restore_best_weights=False)\n",
    "\n",
    "rnn2_hist = rnn2.fit(xrnn_train, ybm_train, batch_size=rnn2_batch_size, epochs=rnn2_epochs, validation_split=rnn2_val_split, callbacks=[rnn2_es], verbose=1)\n",
    "rnn2_val_score = rnn2.evaluate(xrnn_test, ybm_test, verbose=0)\n",
    "\n",
    "print('{}-Layer LSTM'.format(rnn2_layers))\n",
    "print('------------------------')\n",
    "print('Test loss score: {0:.4f}'.format(rnn2_val_score[0]))\n",
    "print('Test accuracy:   {0:.4f}'.format(rnn2_val_score[1]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

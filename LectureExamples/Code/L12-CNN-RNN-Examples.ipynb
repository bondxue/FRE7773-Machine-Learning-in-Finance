{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN and RNN Examples\n",
    "**Make sure you have activated the correct python envorinment**\n",
    "\n",
    "+ Using the keras Sequential API and MNIST data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "np.random.seed(42)\n",
    "\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, SimpleRNN, LSTM\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data\n",
    "\n",
    "MNIST is a dataset of 60,000 28x28 grayscale images of handwritten digits, along with a test set of 10,000 images.\n",
    "\n",
    "Load the MNIST data using keras. The first time the data are downloaded and cached.  \n",
    "Subsequent times the data are loaded from the cache."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the date and split into training/testing sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert the target values vector to binary class matrix\n",
    "y_train is a vector of size 60,000.  \n",
    "It gets mapped to a 60,000 x 10 matrix of 0s and 1s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Targets before: \n",
      "[5 0 4 1 9]\n",
      "Targets after: \n",
      "[[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "n_classes = 10\n",
    "\n",
    "print(\"Targets before: \\n{}\".format(y_train[:5]))\n",
    "ybm_train = to_categorical(y_train, n_classes)\n",
    "ybm_test = to_categorical(y_test, n_classes)\n",
    "print(\"Targets after: \\n{}\".format(ybm_train[:5]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reshape and normalize the input data\n",
    "The inputs are fed to the CNN as 2D images with dimensions image_size x image_size (28x28).  \n",
    "The third singleton dimension is the channel, which in our case is the grayscale value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = x_train.shape[1]\n",
    "xcnn_train = np.reshape(x_train,[-1, image_size, image_size, 1])\n",
    "xcnn_test = np.reshape(x_test,[-1, image_size, image_size, 1])\n",
    "xcnn_train = xcnn_train.astype('float32') / 255\n",
    "xcnn_test = xcnn_test.astype('float32') / 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct the CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 28, 28, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 6272)              0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 6272)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                62730     \n",
      "=================================================================\n",
      "Total params: 63,050\n",
      "Trainable params: 63,050\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# parameters\n",
    "cnn_input_shape = (image_size, image_size, 1)\n",
    "cnn1_layers = 1\n",
    "kernel_size = 3\n",
    "n_filters = 32\n",
    "cnn1_drop_rate = 0.4\n",
    "\n",
    "cnn1 = Sequential()\n",
    "cnn1.add(Conv2D(input_shape=cnn_input_shape, filters=n_filters, kernel_size=kernel_size,  padding='same', activation='relu'))\n",
    "cnn1.add(MaxPooling2D())\n",
    "for i in range(cnn1_layers - 1):\n",
    "    cnn1.add(Conv2D(filters=n_filters, kernel_size=kernel_size,  padding='same', activation='relu'))\n",
    "    cnn1.add(Dropout(cnn1_drop_rate))\n",
    "    cnn1.add(MaxPooling2D())\n",
    "cnn1.add(Flatten())\n",
    "cnn1.add(Dropout(cnn1_drop_rate))\n",
    "cnn1.add(Dense(n_classes, activation='softmax'))\n",
    "cnn1.summary()\n",
    "\n",
    "# the number of parameters is: n_classes x (input_dim + 1)\n",
    "# each node has its own bias (therefore +1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile and fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/10\n",
      "54000/54000 [==============================] - 30s 555us/step - loss: 0.7378 - acc: 0.8135 - val_loss: 0.2464 - val_acc: 0.9307\n",
      "Epoch 2/10\n",
      "54000/54000 [==============================] - 31s 577us/step - loss: 0.2816 - acc: 0.9178 - val_loss: 0.1752 - val_acc: 0.9518\n",
      "Epoch 3/10\n",
      "54000/54000 [==============================] - 33s 609us/step - loss: 0.2068 - acc: 0.9405 - val_loss: 0.1348 - val_acc: 0.9648\n",
      "Epoch 4/10\n",
      "54000/54000 [==============================] - 33s 617us/step - loss: 0.1638 - acc: 0.9522 - val_loss: 0.1076 - val_acc: 0.9737\n",
      "Epoch 5/10\n",
      "54000/54000 [==============================] - 33s 611us/step - loss: 0.1397 - acc: 0.9605 - val_loss: 0.0939 - val_acc: 0.9760\n",
      "Epoch 6/10\n",
      "54000/54000 [==============================] - 35s 642us/step - loss: 0.1215 - acc: 0.9653 - val_loss: 0.0842 - val_acc: 0.9777\n",
      "Epoch 7/10\n",
      "54000/54000 [==============================] - 39s 720us/step - loss: 0.1117 - acc: 0.9680 - val_loss: 0.0774 - val_acc: 0.9798\n",
      "Epoch 8/10\n",
      "54000/54000 [==============================] - 39s 720us/step - loss: 0.1035 - acc: 0.9701 - val_loss: 0.0763 - val_acc: 0.9797\n",
      "Epoch 9/10\n",
      "54000/54000 [==============================] - 35s 651us/step - loss: 0.0977 - acc: 0.9712 - val_loss: 0.0708 - val_acc: 0.9820\n",
      "Epoch 10/10\n",
      "54000/54000 [==============================] - 35s 657us/step - loss: 0.0935 - acc: 0.9726 - val_loss: 0.0676 - val_acc: 0.9822\n",
      "1-Layer CNN\n",
      "------------------------\n",
      "Test loss score: 0.0707\n",
      "Test accuracy:   0.9780\n"
     ]
    }
   ],
   "source": [
    "# compile, fit and evaluate\n",
    "cnn1.compile(optimizer='nadam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "cnn1_batch_size = 1000\n",
    "cnn1_epochs = 10\n",
    "cnn1_val_split = 0.1 \n",
    "# create an early stopping callback\n",
    "cnn1_es = EarlyStopping(monitor='val_loss', min_delta=0, patience=3, mode='auto', baseline=None, restore_best_weights=False)\n",
    "\n",
    "cnn1_hist = cnn1.fit(xcnn_train, ybm_train, batch_size=cnn1_batch_size, epochs=cnn1_epochs, validation_split=cnn1_val_split, callbacks=[cnn1_es], verbose=1)\n",
    "cnn1_val_score = cnn1.evaluate(xcnn_test, ybm_test, verbose=0)\n",
    "\n",
    "print('{}-Layer CNN'.format(cnn1_layers))\n",
    "print('------------------------')\n",
    "print('Test loss score: {0:.4f}'.format(cnn1_val_score[0]))\n",
    "print('Test accuracy:   {0:.4f}'.format(cnn1_val_score[1]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN predictions and true values\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[7, 2, 1, 0, 4, 1, 4, 9, 6, 9, 0, 6, 9, 0, 1, 5, 9, 7, 8, 4]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[7, 2, 1, 0, 4, 1, 4, 9, 5, 9, 0, 6, 9, 0, 1, 5, 9, 7, 3, 4]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cnn1_pred = cnn1.predict(xcnn_test[:20])\n",
    "cnn1_ypred = np.argmax(cnn1_pred, axis=1)\n",
    "\n",
    "print('CNN predictions and true values')\n",
    "display(cnn1_ypred.tolist())\n",
    "display(y_test[:20].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predited values: [7 8 4]\n",
      "True values: [7 3 4]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot a few digits and print the true values\n",
    "idigits = [17, 18, 19]\n",
    "\n",
    "fig = plt.figure(figsize=(12, 6))\n",
    "for i in range(len(idigits)):\n",
    "    ax = fig.add_subplot(1, len(idigits), i + 1)\n",
    "    ax.imshow(x_test[idigits[i]], cmap = plt.cm.binary, interpolation=\"nearest\")\n",
    "    ax.axis(\"off\")\n",
    "print('Predited values: {}'.format(cnn1_ypred[idigits]))\n",
    "print('True values: {}'.format(y_test[idigits]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reshape and normalize the input data\n",
    "The inputs are fed to the RNN as 2D images with dimensions image_size x image_size (28x28).  \n",
    "The first dimension is the 'time'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "xrnn_train = np.reshape(x_train,[-1, image_size, image_size])\n",
    "xrnn_test = np.reshape(x_test,[-1, image_size, image_size])\n",
    "xrnn_train = xrnn_train.astype('float32') / 255\n",
    "xrnn_test = xrnn_test.astype('float32') / 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct a SimpleRNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "simple_rnn_1 (SimpleRNN)     (None, 256)               72960     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 75,530\n",
      "Trainable params: 75,530\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# parameters\n",
    "rnn_input_shape = (image_size, image_size)\n",
    "rnn1_layers = 1\n",
    "n_units = 256\n",
    "rnn1_drop_rate = 0.4\n",
    "\n",
    "rnn1 = Sequential()\n",
    "rnn1.add(SimpleRNN(input_shape=rnn_input_shape, units=n_units, activation='relu'))\n",
    "rnn1.add(Dropout(rnn1_drop_rate))\n",
    "for i in range(rnn1_layers - 1):\n",
    "    rnn1.add(SimpleRNN(input_shape=rnn_input_shape, units=n_units, activation='relu'))\n",
    "    rnn1.add(Dropout(rnn1_drop_rate))\n",
    "rnn1.add(Dense(n_classes, activation='softmax'))\n",
    "rnn1.summary()\n",
    "\n",
    "# the number of parameters is: n_classes x (input_dim + 1)\n",
    "# each node has its own bias (therefore +1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile and fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/10\n",
      "54000/54000 [==============================] - 17s 310us/step - loss: 1.5691 - acc: 0.4451 - val_loss: 0.6711 - val_acc: 0.7627\n",
      "Epoch 2/10\n",
      "54000/54000 [==============================] - 18s 331us/step - loss: 0.6986 - acc: 0.7640 - val_loss: 0.3194 - val_acc: 0.9025\n",
      "Epoch 3/10\n",
      "54000/54000 [==============================] - 18s 339us/step - loss: 0.3937 - acc: 0.8810 - val_loss: 0.3035 - val_acc: 0.9102\n",
      "Epoch 4/10\n",
      "54000/54000 [==============================] - 16s 298us/step - loss: 0.3094 - acc: 0.9094 - val_loss: 0.6969 - val_acc: 0.7785\n",
      "Epoch 5/10\n",
      "54000/54000 [==============================] - 15s 272us/step - loss: 0.2927 - acc: 0.9153 - val_loss: 0.1266 - val_acc: 0.9648\n",
      "Epoch 6/10\n",
      "54000/54000 [==============================] - 17s 321us/step - loss: 0.1321 - acc: 0.9634 - val_loss: 0.1095 - val_acc: 0.9697\n",
      "Epoch 7/10\n",
      "54000/54000 [==============================] - 16s 303us/step - loss: 0.1118 - acc: 0.9687 - val_loss: 0.0892 - val_acc: 0.9753\n",
      "Epoch 8/10\n",
      "54000/54000 [==============================] - 16s 297us/step - loss: 0.3467 - acc: 0.8978 - val_loss: 0.1111 - val_acc: 0.9697\n",
      "Epoch 9/10\n",
      "54000/54000 [==============================] - 16s 300us/step - loss: 0.1221 - acc: 0.9658 - val_loss: 0.0855 - val_acc: 0.9760\n",
      "Epoch 10/10\n",
      "54000/54000 [==============================] - 15s 287us/step - loss: 0.0909 - acc: 0.9748 - val_loss: 0.0755 - val_acc: 0.9798\n",
      "1-Layer SimpleRNN\n",
      "------------------------\n",
      "Test loss score: 0.0872\n",
      "Test accuracy:   0.9731\n"
     ]
    }
   ],
   "source": [
    "# compile, fit and evaluate\n",
    "rnn1.compile(optimizer='nadam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "rnn1_batch_size = 1000\n",
    "rnn1_epochs = 10\n",
    "rnn1_val_split = 0.1 \n",
    "# create an early stopping callback\n",
    "rnn1_es = EarlyStopping(monitor='val_loss', min_delta=0, patience=3, mode='auto', baseline=None, restore_best_weights=False)\n",
    "\n",
    "rnn1_hist = rnn1.fit(xrnn_train, ybm_train, batch_size=rnn1_batch_size, epochs=rnn1_epochs, validation_split=rnn1_val_split, callbacks=[rnn1_es], verbose=1)\n",
    "rnn1_val_score = rnn1.evaluate(xrnn_test, ybm_test, verbose=0)\n",
    "\n",
    "print('{}-Layer SimpleRNN'.format(rnn1_layers))\n",
    "print('------------------------')\n",
    "print('Test loss score: {0:.4f}'.format(rnn1_val_score[0]))\n",
    "print('Test accuracy:   {0:.4f}'.format(rnn1_val_score[1]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LSTM is a drop-in replacement for SimpleRNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 256)               291840    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 294,410\n",
      "Trainable params: 294,410\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# parameters\n",
    "rnn_input_shape = (image_size, image_size)\n",
    "rnn2_layers = 1\n",
    "n_units = 256\n",
    "rnn2_drop_rate = 0.4\n",
    "\n",
    "rnn2 = Sequential()\n",
    "rnn2.add(LSTM(input_shape=rnn_input_shape, units=n_units, activation='relu'))\n",
    "rnn2.add(Dropout(rnn2_drop_rate))\n",
    "for i in range(rnn2_layers - 1):\n",
    "    rnn2.add(SimpleRNN(input_shape=rnn_input_shape, units=n_units, activation='relu'))\n",
    "    rnn2.add(Dropout(rnn2_drop_rate))\n",
    "rnn2.add(Dense(n_classes, activation='softmax'))\n",
    "rnn2.summary()\n",
    "\n",
    "# the number of parameters is: n_classes x (input_dim + 1)\n",
    "# each node has its own bias (therefore +1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/10\n",
      "54000/54000 [==============================] - 70s 1ms/step - loss: 2.1541 - acc: 0.3024 - val_loss: 1.7647 - val_acc: 0.3960\n",
      "Epoch 2/10\n",
      "54000/54000 [==============================] - 65s 1ms/step - loss: 1.5826 - acc: 0.4680 - val_loss: 0.8452 - val_acc: 0.7092\n",
      "Epoch 3/10\n",
      "54000/54000 [==============================] - 69s 1ms/step - loss: 1.0846 - acc: 0.6247 - val_loss: 0.5174 - val_acc: 0.8167\n",
      "Epoch 4/10\n",
      "54000/54000 [==============================] - 70s 1ms/step - loss: 0.4640 - acc: 0.8443 - val_loss: 0.3413 - val_acc: 0.8755\n",
      "Epoch 5/10\n",
      "54000/54000 [==============================] - 66s 1ms/step - loss: 0.2889 - acc: 0.9078 - val_loss: 0.1430 - val_acc: 0.9540\n",
      "Epoch 6/10\n",
      "54000/54000 [==============================] - 69s 1ms/step - loss: 0.1937 - acc: 0.9393 - val_loss: 0.1139 - val_acc: 0.9623\n",
      "Epoch 7/10\n",
      "54000/54000 [==============================] - 67s 1ms/step - loss: 0.1586 - acc: 0.9517 - val_loss: 0.0866 - val_acc: 0.9748\n",
      "Epoch 8/10\n",
      "54000/54000 [==============================] - 66s 1ms/step - loss: 0.1166 - acc: 0.9648 - val_loss: 0.0714 - val_acc: 0.9792\n",
      "Epoch 9/10\n",
      "54000/54000 [==============================] - 73s 1ms/step - loss: 0.0886 - acc: 0.9741 - val_loss: 0.0843 - val_acc: 0.9752\n",
      "Epoch 10/10\n",
      "54000/54000 [==============================] - 64s 1ms/step - loss: 0.1051 - acc: 0.9686 - val_loss: 0.0564 - val_acc: 0.9840\n",
      "1-Layer LSTM\n",
      "------------------------\n",
      "Test loss score: 0.0770\n",
      "Test accuracy:   0.9775\n"
     ]
    }
   ],
   "source": [
    "# compile, fit and evaluate\n",
    "rnn2.compile(optimizer='nadam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "rnn2_batch_size = 1000\n",
    "rnn2_epochs = 10\n",
    "rnn2_val_split = 0.1 \n",
    "# create an early stopping callback\n",
    "rnn2_es = EarlyStopping(monitor='val_loss', min_delta=0, patience=3, mode='auto', baseline=None, restore_best_weights=False)\n",
    "\n",
    "rnn2_hist = rnn2.fit(xrnn_train, ybm_train, batch_size=rnn2_batch_size, epochs=rnn2_epochs, validation_split=rnn2_val_split, callbacks=[rnn2_es], verbose=1)\n",
    "rnn2_val_score = rnn2.evaluate(xrnn_test, ybm_test, verbose=0)\n",
    "\n",
    "print('{}-Layer LSTM'.format(rnn2_layers))\n",
    "print('------------------------')\n",
    "print('Test loss score: {0:.4f}'.format(rnn2_val_score[0]))\n",
    "print('Test accuracy:   {0:.4f}'.format(rnn2_val_score[1]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
